{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684d8f2b",
   "metadata": {},
   "source": [
    "Project Title: Sentiment Analysis using Recurrent Neural Networks (RNNs) for Movie Reviews.\n",
    "Saurabh Chaudhary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4901b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb627c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing movie reviews data\n",
    "IMDB = pd.read_csv(\"C:\\\\Users\\\\89tom\\\\OneDrive\\\\Desktop\\\\Pace\\\\DeepLearningCS672\\\\project 3\\\\IMDB Dataset.csv\")\n",
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615ca193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "701cb944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values.\n",
    "IMDB.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8446606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting sentiments into numbers\n",
    "sentiments_num = list(map(lambda x: 1 if x == 'positive' else 0, IMDB['sentiment'].values))\n",
    "\n",
    "# adding numbers sentiments into dataframe\n",
    "\n",
    "IMDB['sentiments_num'] = sentiments_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f0aa74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing reviews for model\n",
    "port_stem = PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    stemmed_text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    stemmed_text = stemmed_text.lower()\n",
    "    stemmed_text = stemmed_text.split()\n",
    "    stemmed_text = [port_stem.stem(word) for word in stemmed_text if not word in stopwords.words('english')]\n",
    "    stemmed_text = ' '.join(stemmed_text)\n",
    "\n",
    "    return(stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04020324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing review data and adding to new column\n",
    "IMDB['content'] = (IMDB['review']).apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214c7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resting index\n",
    "IMDB.reset_index(inplace = True)\n",
    "\n",
    "# selecting Necessary data only\n",
    "IMDB = IMDB[['content','sentiments_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8770776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data into training and testing data\n",
    "IMDB_train, IMDB_test = train_test_split(IMDB,test_size = 0.25, stratify=IMDB['sentiments_num'])\n",
    "\n",
    "X_train = IMDB_train['content']\n",
    "X_test = IMDB_test['content']\n",
    "\n",
    "y_train = IMDB_train['sentiments_num']\n",
    "y_test = IMDB_test['sentiments_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c58527a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    18750\n",
      "0    18750\n",
      "Name: sentiments_num, dtype: int64\n",
      "0    6250\n",
      "1    6250\n",
      "Name: sentiments_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7957dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# converting words into token\n",
    "tokenizer = Tokenizer(num_words=500, oov_token = \"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# creating sequences\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "\n",
    "# padding sequences\n",
    "padded = pad_sequences(sequences, maxlen=10, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7a74cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1172/1172 [==============================] - 7s 4ms/step - loss: 0.6054 - accuracy: 0.6519\n",
      "Epoch 2/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5796 - accuracy: 0.6818\n",
      "Epoch 3/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5748 - accuracy: 0.6840\n",
      "Epoch 4/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5688 - accuracy: 0.6854\n",
      "Epoch 5/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5646 - accuracy: 0.6877\n",
      "Epoch 6/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5614 - accuracy: 0.6894\n",
      "Epoch 7/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5588 - accuracy: 0.6926\n",
      "Epoch 8/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5559 - accuracy: 0.6926\n",
      "Epoch 9/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5530 - accuracy: 0.6934\n",
      "Epoch 10/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5503 - accuracy: 0.6967\n",
      "Epoch 11/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5477 - accuracy: 0.6978\n",
      "Epoch 12/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5450 - accuracy: 0.7004\n",
      "Epoch 13/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5420 - accuracy: 0.7035\n",
      "Epoch 14/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5393 - accuracy: 0.7047\n",
      "Epoch 15/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5369 - accuracy: 0.7062\n",
      "Epoch 16/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5350 - accuracy: 0.7083\n",
      "Epoch 17/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5330 - accuracy: 0.7085\n",
      "Epoch 18/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5299 - accuracy: 0.7123\n",
      "Epoch 19/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5270 - accuracy: 0.7163\n",
      "Epoch 20/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5243 - accuracy: 0.7177\n",
      "Epoch 21/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5201 - accuracy: 0.7203\n",
      "Epoch 22/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5164 - accuracy: 0.7227\n",
      "Epoch 23/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5130 - accuracy: 0.7247\n",
      "Epoch 24/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5084 - accuracy: 0.7289\n",
      "Epoch 25/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5036 - accuracy: 0.7310\n",
      "Epoch 26/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4998 - accuracy: 0.7340\n",
      "Epoch 27/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4952 - accuracy: 0.7379\n",
      "Epoch 28/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4900 - accuracy: 0.7417\n",
      "Epoch 29/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4847 - accuracy: 0.7433\n",
      "Epoch 30/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4801 - accuracy: 0.7463\n",
      "Epoch 31/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4750 - accuracy: 0.7503\n",
      "Epoch 32/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4696 - accuracy: 0.7542\n",
      "Epoch 33/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4641 - accuracy: 0.7573\n",
      "Epoch 34/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4597 - accuracy: 0.7605\n",
      "Epoch 35/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4544 - accuracy: 0.7630\n",
      "Epoch 36/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4489 - accuracy: 0.7661\n",
      "Epoch 37/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4443 - accuracy: 0.7694\n",
      "Epoch 38/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4388 - accuracy: 0.7726\n",
      "Epoch 39/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4330 - accuracy: 0.7777\n",
      "Epoch 40/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4287 - accuracy: 0.7817\n",
      "Epoch 41/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4241 - accuracy: 0.7819\n",
      "Epoch 42/250\n",
      "1172/1172 [==============================] - 6s 6ms/step - loss: 0.4188 - accuracy: 0.7862\n",
      "Epoch 43/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4146 - accuracy: 0.7890\n",
      "Epoch 44/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4090 - accuracy: 0.7922\n",
      "Epoch 45/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4034 - accuracy: 0.7972\n",
      "Epoch 46/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4004 - accuracy: 0.7978\n",
      "Epoch 47/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3943 - accuracy: 0.8009\n",
      "Epoch 48/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3903 - accuracy: 0.8040\n",
      "Epoch 49/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3857 - accuracy: 0.8069\n",
      "Epoch 50/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3810 - accuracy: 0.8085\n",
      "Epoch 51/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3759 - accuracy: 0.8127\n",
      "Epoch 52/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3733 - accuracy: 0.8133\n",
      "Epoch 53/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3689 - accuracy: 0.8153\n",
      "Epoch 54/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3623 - accuracy: 0.8194\n",
      "Epoch 55/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3584 - accuracy: 0.8212\n",
      "Epoch 56/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3550 - accuracy: 0.8252\n",
      "Epoch 57/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3501 - accuracy: 0.8278\n",
      "Epoch 58/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.3475 - accuracy: 0.8291\n",
      "Epoch 59/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.3464 - accuracy: 0.8291\n",
      "Epoch 60/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3382 - accuracy: 0.8340\n",
      "Epoch 61/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3353 - accuracy: 0.8360\n",
      "Epoch 62/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3325 - accuracy: 0.8381\n",
      "Epoch 63/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.3300 - accuracy: 0.8388\n",
      "Epoch 64/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3275 - accuracy: 0.8410\n",
      "Epoch 65/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3233 - accuracy: 0.8431\n",
      "Epoch 66/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3167 - accuracy: 0.8445\n",
      "Epoch 67/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3159 - accuracy: 0.8477\n",
      "Epoch 68/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3125 - accuracy: 0.8503\n",
      "Epoch 69/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3084 - accuracy: 0.8517\n",
      "Epoch 70/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3060 - accuracy: 0.8531\n",
      "Epoch 71/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3066 - accuracy: 0.8522\n",
      "Epoch 72/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3010 - accuracy: 0.8553\n",
      "Epoch 73/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2975 - accuracy: 0.8578\n",
      "Epoch 74/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2955 - accuracy: 0.8601\n",
      "Epoch 75/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.2914 - accuracy: 0.8612\n",
      "Epoch 76/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2936 - accuracy: 0.8607\n",
      "Epoch 77/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2847 - accuracy: 0.8651\n",
      "Epoch 78/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2847 - accuracy: 0.8654\n",
      "Epoch 79/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2842 - accuracy: 0.8651\n",
      "Epoch 80/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2768 - accuracy: 0.8695\n",
      "Epoch 81/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2761 - accuracy: 0.8697\n",
      "Epoch 82/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2763 - accuracy: 0.8705\n",
      "Epoch 83/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2714 - accuracy: 0.8722\n",
      "Epoch 84/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2706 - accuracy: 0.8723\n",
      "Epoch 85/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2681 - accuracy: 0.8746\n",
      "Epoch 86/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2621 - accuracy: 0.8765\n",
      "Epoch 87/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2629 - accuracy: 0.8774\n",
      "Epoch 88/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2630 - accuracy: 0.8778\n",
      "Epoch 89/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2574 - accuracy: 0.8799\n",
      "Epoch 90/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2607 - accuracy: 0.8789\n",
      "Epoch 91/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2541 - accuracy: 0.8810\n",
      "Epoch 92/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2525 - accuracy: 0.8829\n",
      "Epoch 93/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2492 - accuracy: 0.8855\n",
      "Epoch 94/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2521 - accuracy: 0.8829\n",
      "Epoch 95/250\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.2479 - accuracy: 0.8857\n",
      "Epoch 96/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.2441 - accuracy: 0.8892\n",
      "Epoch 97/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2440 - accuracy: 0.8892\n",
      "Epoch 98/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2379 - accuracy: 0.8913\n",
      "Epoch 99/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2417 - accuracy: 0.8896\n",
      "Epoch 100/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2407 - accuracy: 0.8909\n",
      "Epoch 101/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2371 - accuracy: 0.8902\n",
      "Epoch 102/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2318 - accuracy: 0.8939\n",
      "Epoch 103/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2340 - accuracy: 0.8943\n",
      "Epoch 104/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2332 - accuracy: 0.8950\n",
      "Epoch 105/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2274 - accuracy: 0.8973\n",
      "Epoch 106/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2289 - accuracy: 0.8965\n",
      "Epoch 107/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.2222 - accuracy: 0.9003\n",
      "Epoch 108/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2226 - accuracy: 0.8996\n",
      "Epoch 109/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2225 - accuracy: 0.8999\n",
      "Epoch 110/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2248 - accuracy: 0.8998\n",
      "Epoch 111/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2195 - accuracy: 0.9019\n",
      "Epoch 112/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2192 - accuracy: 0.9021\n",
      "Epoch 113/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2193 - accuracy: 0.9027\n",
      "Epoch 114/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.2189 - accuracy: 0.9029\n",
      "Epoch 115/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2140 - accuracy: 0.9053\n",
      "Epoch 116/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2133 - accuracy: 0.9049\n",
      "Epoch 117/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2130 - accuracy: 0.9069\n",
      "Epoch 118/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2085 - accuracy: 0.9081\n",
      "Epoch 119/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2084 - accuracy: 0.9073\n",
      "Epoch 120/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.2059 - accuracy: 0.9083\n",
      "Epoch 121/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2087 - accuracy: 0.9082\n",
      "Epoch 122/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2031 - accuracy: 0.9106\n",
      "Epoch 123/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2030 - accuracy: 0.9100\n",
      "Epoch 124/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1990 - accuracy: 0.9130\n",
      "Epoch 125/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2081 - accuracy: 0.9084\n",
      "Epoch 126/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2041 - accuracy: 0.9103\n",
      "Epoch 127/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2007 - accuracy: 0.9121\n",
      "Epoch 128/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1949 - accuracy: 0.9147\n",
      "Epoch 129/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1999 - accuracy: 0.9126\n",
      "Epoch 130/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1947 - accuracy: 0.9149\n",
      "Epoch 131/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1930 - accuracy: 0.9149\n",
      "Epoch 132/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1960 - accuracy: 0.9145\n",
      "Epoch 133/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1922 - accuracy: 0.9155\n",
      "Epoch 134/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1947 - accuracy: 0.9154\n",
      "Epoch 135/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1905 - accuracy: 0.9165\n",
      "Epoch 136/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1911 - accuracy: 0.9170\n",
      "Epoch 137/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1896 - accuracy: 0.9170\n",
      "Epoch 138/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1860 - accuracy: 0.9196\n",
      "Epoch 139/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1868 - accuracy: 0.9191\n",
      "Epoch 140/250\n",
      "1172/1172 [==============================] - 6s 6ms/step - loss: 0.1879 - accuracy: 0.9186\n",
      "Epoch 141/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1846 - accuracy: 0.9207\n",
      "Epoch 142/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1926 - accuracy: 0.9168\n",
      "Epoch 143/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1801 - accuracy: 0.9225\n",
      "Epoch 144/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1789 - accuracy: 0.9224\n",
      "Epoch 145/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1840 - accuracy: 0.9219\n",
      "Epoch 146/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1810 - accuracy: 0.9229\n",
      "Epoch 147/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1749 - accuracy: 0.9241\n",
      "Epoch 148/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1859 - accuracy: 0.9202\n",
      "Epoch 149/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1766 - accuracy: 0.9246\n",
      "Epoch 150/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1705 - accuracy: 0.9260\n",
      "Epoch 151/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1769 - accuracy: 0.9235\n",
      "Epoch 152/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1784 - accuracy: 0.9243\n",
      "Epoch 153/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1753 - accuracy: 0.9248\n",
      "Epoch 154/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1761 - accuracy: 0.9254\n",
      "Epoch 155/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1728 - accuracy: 0.9273\n",
      "Epoch 156/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1775 - accuracy: 0.9244\n",
      "Epoch 157/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1749 - accuracy: 0.9257\n",
      "Epoch 158/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1647 - accuracy: 0.9293\n",
      "Epoch 159/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1686 - accuracy: 0.9285\n",
      "Epoch 160/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1728 - accuracy: 0.9273\n",
      "Epoch 161/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1666 - accuracy: 0.9294\n",
      "Epoch 162/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1717 - accuracy: 0.9265\n",
      "Epoch 163/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1707 - accuracy: 0.9289\n",
      "Epoch 164/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1708 - accuracy: 0.9287\n",
      "Epoch 165/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1616 - accuracy: 0.9308\n",
      "Epoch 166/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1660 - accuracy: 0.9310\n",
      "Epoch 167/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1593 - accuracy: 0.9321\n",
      "Epoch 168/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1695 - accuracy: 0.9284\n",
      "Epoch 169/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1721 - accuracy: 0.9290\n",
      "Epoch 170/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1576 - accuracy: 0.9318\n",
      "Epoch 171/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1676 - accuracy: 0.9309\n",
      "Epoch 172/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1683 - accuracy: 0.9302\n",
      "Epoch 173/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1607 - accuracy: 0.9330\n",
      "Epoch 174/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1530 - accuracy: 0.9351\n",
      "Epoch 175/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1658 - accuracy: 0.9298\n",
      "Epoch 176/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1631 - accuracy: 0.9325\n",
      "Epoch 177/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1583 - accuracy: 0.9338\n",
      "Epoch 178/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1577 - accuracy: 0.9343\n",
      "Epoch 179/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1561 - accuracy: 0.9346\n",
      "Epoch 180/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1626 - accuracy: 0.9308\n",
      "Epoch 181/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1631 - accuracy: 0.9322\n",
      "Epoch 182/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1534 - accuracy: 0.9347\n",
      "Epoch 183/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1548 - accuracy: 0.9346\n",
      "Epoch 184/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1630 - accuracy: 0.9319\n",
      "Epoch 185/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1501 - accuracy: 0.9356\n",
      "Epoch 186/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1649 - accuracy: 0.9306\n",
      "Epoch 187/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1533 - accuracy: 0.9353\n",
      "Epoch 188/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1491 - accuracy: 0.9366\n",
      "Epoch 189/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1574 - accuracy: 0.9338\n",
      "Epoch 190/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1535 - accuracy: 0.9347\n",
      "Epoch 191/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1513 - accuracy: 0.9358\n",
      "Epoch 192/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1480 - accuracy: 0.9384\n",
      "Epoch 193/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1593 - accuracy: 0.9329\n",
      "Epoch 194/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1516 - accuracy: 0.9374\n",
      "Epoch 195/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1577 - accuracy: 0.9348\n",
      "Epoch 196/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1542 - accuracy: 0.9353\n",
      "Epoch 197/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1457 - accuracy: 0.9392\n",
      "Epoch 198/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1397 - accuracy: 0.9414\n",
      "Epoch 199/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1516 - accuracy: 0.9379\n",
      "Epoch 200/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1470 - accuracy: 0.9386\n",
      "Epoch 201/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1509 - accuracy: 0.9386\n",
      "Epoch 202/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1597 - accuracy: 0.9356\n",
      "Epoch 203/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1502 - accuracy: 0.9373\n",
      "Epoch 204/250\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.1364 - accuracy: 0.9441\n",
      "Epoch 205/250\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.1528 - accuracy: 0.9376\n",
      "Epoch 206/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1375 - accuracy: 0.9433\n",
      "Epoch 207/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1530 - accuracy: 0.9378\n",
      "Epoch 208/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1440 - accuracy: 0.9399\n",
      "Epoch 209/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1438 - accuracy: 0.9405\n",
      "Epoch 210/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1501 - accuracy: 0.9392\n",
      "Epoch 211/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1495 - accuracy: 0.9369\n",
      "Epoch 212/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1338 - accuracy: 0.9447\n",
      "Epoch 213/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1371 - accuracy: 0.9432\n",
      "Epoch 214/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1491 - accuracy: 0.9378\n",
      "Epoch 215/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1379 - accuracy: 0.9424\n",
      "Epoch 216/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1459 - accuracy: 0.9399\n",
      "Epoch 217/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1370 - accuracy: 0.9427\n",
      "Epoch 218/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1517 - accuracy: 0.9379\n",
      "Epoch 219/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1481 - accuracy: 0.9401\n",
      "Epoch 220/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1475 - accuracy: 0.9382\n",
      "Epoch 221/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1347 - accuracy: 0.9455\n",
      "Epoch 222/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1463 - accuracy: 0.9410\n",
      "Epoch 223/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1446 - accuracy: 0.9420\n",
      "Epoch 224/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1289 - accuracy: 0.9479\n",
      "Epoch 225/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1400 - accuracy: 0.9427\n",
      "Epoch 226/250\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.1284 - accuracy: 0.9472\n",
      "Epoch 227/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1530 - accuracy: 0.9387\n",
      "Epoch 228/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1409 - accuracy: 0.9421\n",
      "Epoch 229/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1320 - accuracy: 0.9464\n",
      "Epoch 230/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1385 - accuracy: 0.9425\n",
      "Epoch 231/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1376 - accuracy: 0.9453\n",
      "Epoch 232/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1391 - accuracy: 0.9423\n",
      "Epoch 233/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1360 - accuracy: 0.9436\n",
      "Epoch 234/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1388 - accuracy: 0.9429\n",
      "Epoch 235/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1360 - accuracy: 0.9446\n",
      "Epoch 236/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1366 - accuracy: 0.9446\n",
      "Epoch 237/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1373 - accuracy: 0.9434\n",
      "Epoch 238/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1459 - accuracy: 0.9417\n",
      "Epoch 239/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1331 - accuracy: 0.9445\n",
      "Epoch 240/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1302 - accuracy: 0.9472\n",
      "Epoch 241/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1392 - accuracy: 0.9439\n",
      "Epoch 242/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1349 - accuracy: 0.9453\n",
      "Epoch 243/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1339 - accuracy: 0.9453\n",
      "Epoch 244/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1278 - accuracy: 0.9486\n",
      "Epoch 245/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1300 - accuracy: 0.9468\n",
      "Epoch 246/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1343 - accuracy: 0.9448\n",
      "Epoch 247/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1301 - accuracy: 0.9484\n",
      "Epoch 248/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1323 - accuracy: 0.9474\n",
      "Epoch 249/250\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.1394 - accuracy: 0.9446\n",
      "Epoch 250/250\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.1277 - accuracy: 0.9481\n",
      "391/391 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Desiging and traing RNN model\n",
    "RNN_model = Sequential()\n",
    "RNN_model.add(Embedding(input_dim=500, output_dim=16, input_length=10))\n",
    "RNN_model.add(LSTM(32))\n",
    "RNN_model.add(Dense(1,activation='sigmoid'))\n",
    "RNN_model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "RNN_model.fit(padded,y_train,epochs=250)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "padded_test = pad_sequences(sequences_test, maxlen=10, padding='post', truncating='post')\n",
    "RNN_pred = RNN_model.predict(padded_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd090cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1172/1172 [==============================] - 7s 4ms/step - loss: 0.6029 - accuracy: 0.6586\n",
      "Epoch 2/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5787 - accuracy: 0.6817\n",
      "Epoch 3/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5720 - accuracy: 0.6856\n",
      "Epoch 4/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5661 - accuracy: 0.6905\n",
      "Epoch 5/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5621 - accuracy: 0.6902\n",
      "Epoch 6/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5580 - accuracy: 0.6922\n",
      "Epoch 7/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5539 - accuracy: 0.6948\n",
      "Epoch 8/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5502 - accuracy: 0.6969\n",
      "Epoch 9/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5466 - accuracy: 0.7023\n",
      "Epoch 10/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5428 - accuracy: 0.7036\n",
      "Epoch 11/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5403 - accuracy: 0.7074\n",
      "Epoch 12/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5362 - accuracy: 0.7086\n",
      "Epoch 13/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5326 - accuracy: 0.7129\n",
      "Epoch 14/50\n",
      "1172/1172 [==============================] - 6s 6ms/step - loss: 0.5280 - accuracy: 0.7157\n",
      "Epoch 15/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5240 - accuracy: 0.7190\n",
      "Epoch 16/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5187 - accuracy: 0.7234\n",
      "Epoch 17/50\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.5129 - accuracy: 0.7302\n",
      "Epoch 18/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.5068 - accuracy: 0.7325\n",
      "Epoch 19/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.5011 - accuracy: 0.7375\n",
      "Epoch 20/50\n",
      "1172/1172 [==============================] - 6s 6ms/step - loss: 0.4951 - accuracy: 0.7414\n",
      "Epoch 21/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4888 - accuracy: 0.7462\n",
      "Epoch 22/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4819 - accuracy: 0.7499\n",
      "Epoch 23/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4755 - accuracy: 0.7554\n",
      "Epoch 24/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4687 - accuracy: 0.7584\n",
      "Epoch 25/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4610 - accuracy: 0.7662\n",
      "Epoch 26/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4532 - accuracy: 0.7698\n",
      "Epoch 27/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.4450 - accuracy: 0.7780\n",
      "Epoch 28/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7822\n",
      "Epoch 29/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4294 - accuracy: 0.7861\n",
      "Epoch 30/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4207 - accuracy: 0.7918\n",
      "Epoch 31/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.4131 - accuracy: 0.7949\n",
      "Epoch 32/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4043 - accuracy: 0.8012\n",
      "Epoch 33/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3961 - accuracy: 0.8067\n",
      "Epoch 34/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3888 - accuracy: 0.8130\n",
      "Epoch 35/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3786 - accuracy: 0.8182\n",
      "Epoch 36/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3720 - accuracy: 0.8206\n",
      "Epoch 37/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3635 - accuracy: 0.8260\n",
      "Epoch 38/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3565 - accuracy: 0.8288\n",
      "Epoch 39/50\n",
      "1172/1172 [==============================] - 5s 5ms/step - loss: 0.3487 - accuracy: 0.8350\n",
      "Epoch 40/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3415 - accuracy: 0.8388\n",
      "Epoch 41/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3337 - accuracy: 0.8442\n",
      "Epoch 42/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3268 - accuracy: 0.8458\n",
      "Epoch 43/50\n",
      "1172/1172 [==============================] - 7s 6ms/step - loss: 0.3190 - accuracy: 0.8497\n",
      "Epoch 44/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.3123 - accuracy: 0.8553\n",
      "Epoch 45/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.3052 - accuracy: 0.8593\n",
      "Epoch 46/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2998 - accuracy: 0.8616\n",
      "Epoch 47/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2906 - accuracy: 0.8675\n",
      "Epoch 48/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2863 - accuracy: 0.8691\n",
      "Epoch 49/50\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.2808 - accuracy: 0.8731\n",
      "Epoch 50/50\n",
      "1172/1172 [==============================] - 6s 5ms/step - loss: 0.2747 - accuracy: 0.8743\n",
      "391/391 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Increasing the embedding dimensions\n",
    "RNN_model = Sequential()\n",
    "RNN_model.add(Embedding(input_dim=500, output_dim=32, input_length=10))\n",
    "RNN_model.add(LSTM(32))\n",
    "RNN_model.add(Dense(1,activation='sigmoid'))\n",
    "RNN_model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "RNN_model.fit(padded,y_train,epochs=50)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "padded_test = pad_sequences(sequences_test, maxlen=10, padding='post', truncating='post')\n",
    "RNN_pred = RNN_model.predict(padded_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d5cfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1172/1172 [==============================] - 13s 9ms/step - loss: 0.6033 - accuracy: 0.6594\n",
      "Epoch 2/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5794 - accuracy: 0.6793\n",
      "Epoch 3/50\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.5721 - accuracy: 0.6855\n",
      "Epoch 4/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5653 - accuracy: 0.6894\n",
      "Epoch 5/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5594 - accuracy: 0.6938\n",
      "Epoch 6/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5546 - accuracy: 0.6959\n",
      "Epoch 7/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5495 - accuracy: 0.6988\n",
      "Epoch 8/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5461 - accuracy: 0.7040\n",
      "Epoch 9/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.5425 - accuracy: 0.7070\n",
      "Epoch 10/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5391 - accuracy: 0.7087\n",
      "Epoch 11/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.5340 - accuracy: 0.7121\n",
      "Epoch 12/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.5294 - accuracy: 0.7149\n",
      "Epoch 13/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.5232 - accuracy: 0.7202\n",
      "Epoch 14/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.5162 - accuracy: 0.7233\n",
      "Epoch 15/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.5097 - accuracy: 0.7283\n",
      "Epoch 16/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.5020 - accuracy: 0.7350\n",
      "Epoch 17/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.4950 - accuracy: 0.7391\n",
      "Epoch 18/50\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.4857 - accuracy: 0.7444\n",
      "Epoch 19/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.4758 - accuracy: 0.7501\n",
      "Epoch 20/50\n",
      "1172/1172 [==============================] - 13s 11ms/step - loss: 0.4646 - accuracy: 0.7583\n",
      "Epoch 21/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.4536 - accuracy: 0.7654\n",
      "Epoch 22/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.4402 - accuracy: 0.7741\n",
      "Epoch 23/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.4287 - accuracy: 0.7805\n",
      "Epoch 24/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.4140 - accuracy: 0.7881\n",
      "Epoch 25/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.4024 - accuracy: 0.7933\n",
      "Epoch 26/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.3863 - accuracy: 0.8033\n",
      "Epoch 27/50\n",
      "1172/1172 [==============================] - 10s 9ms/step - loss: 0.3739 - accuracy: 0.8092\n",
      "Epoch 28/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3611 - accuracy: 0.8162\n",
      "Epoch 29/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.3460 - accuracy: 0.8243\n",
      "Epoch 30/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.3329 - accuracy: 0.8319\n",
      "Epoch 31/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.3211 - accuracy: 0.8376\n",
      "Epoch 32/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.3077 - accuracy: 0.8441\n",
      "Epoch 33/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.2927 - accuracy: 0.8523\n",
      "Epoch 34/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.2852 - accuracy: 0.8567\n",
      "Epoch 35/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.2724 - accuracy: 0.8634\n",
      "Epoch 36/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.2562 - accuracy: 0.8715\n",
      "Epoch 37/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.2502 - accuracy: 0.8773\n",
      "Epoch 38/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.2404 - accuracy: 0.8805\n",
      "Epoch 39/50\n",
      "1172/1172 [==============================] - 10s 9ms/step - loss: 0.2276 - accuracy: 0.8899\n",
      "Epoch 40/50\n",
      "1172/1172 [==============================] - 11s 9ms/step - loss: 0.2174 - accuracy: 0.8945\n",
      "Epoch 41/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.2078 - accuracy: 0.9005\n",
      "Epoch 42/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.2012 - accuracy: 0.9045\n",
      "Epoch 43/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.1917 - accuracy: 0.9096\n",
      "Epoch 44/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.1808 - accuracy: 0.9165\n",
      "Epoch 45/50\n",
      "1172/1172 [==============================] - 12s 11ms/step - loss: 0.1728 - accuracy: 0.9198\n",
      "Epoch 46/50\n",
      "1172/1172 [==============================] - 10s 9ms/step - loss: 0.1642 - accuracy: 0.9249\n",
      "Epoch 47/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.1621 - accuracy: 0.9259\n",
      "Epoch 48/50\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 0.1525 - accuracy: 0.9327\n",
      "Epoch 49/50\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 0.1475 - accuracy: 0.9349\n",
      "Epoch 50/50\n",
      "1172/1172 [==============================] - 10s 9ms/step - loss: 0.1398 - accuracy: 0.9380\n",
      "391/391 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# increasing both the model capacity and the embedding dimensions\n",
    "\n",
    "RNN_model = Sequential()\n",
    "RNN_model.add(Embedding(input_dim=500, output_dim=32, input_length=10))\n",
    "RNN_model.add(LSTM(64,return_sequences = True))\n",
    "RNN_model.add(LSTM(32))\n",
    "RNN_model.add(Dense(1,activation='sigmoid'))\n",
    "RNN_model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "RNN_model.fit(padded,y_train,epochs=50)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
    "padded_test = pad_sequences(sequences_test, maxlen=10, padding='post', truncating='post')\n",
    "RNN_pred = RNN_model.predict(padded_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc172ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6275\n",
      "Precision: 0.6220\n",
      "Recall: 0.6502\n",
      "F1-Score: 0.6358\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3780 2470]\n",
      " [2186 4064]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "threshold = 0.5  \n",
    "binary_predictions = (RNN_pred > threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "precision = precision_score(y_test, binary_predictions)\n",
    "recall = recall_score(y_test, binary_predictions)\n",
    "f1 = f1_score(y_test, binary_predictions)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb85bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to check the sentiments\n",
    "def sentiments(review):\n",
    "    review_test = {'review': [review]}\n",
    "    df_review = pd.DataFrame(review_test)\n",
    "    df_review['review'] = df_review['review'].apply(stemming)\n",
    "    review_test = df_review['review']\n",
    "    tokenizer.fit_on_texts(review_test)\n",
    "    review_sequences = tokenizer.texts_to_sequences(review_test)\n",
    "    padded_review = pad_sequences(review_sequences, maxlen=10, padding='post', truncating='post')\n",
    "    RNN_pred = RNN_model.predict(padded_review)\n",
    "    \n",
    "    if RNN_pred > 0.5:\n",
    "        print('The Review Sentiment is Positive')\n",
    "    elif RNN_pred <= 0.5:\n",
    "        print('The Review Sentiment is Negative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c865c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Killers of the Flower Moon\" is a Western crime drama film co-written and directed by Martin Scorsese, based on the non-fiction book of the same name by David Grann. Starring Leonardo DiCaprio, Robert De Niro, and Lily Gladstone, it touches upon an often overlooked piece of American history in the best way possible thanks to the talents of its director and cast.  In the early 1920s, the discovery of oil on land belonging to the Native American Osage Nation turns the tribe into some of the richest people in the world. This sudden acquisition of wealth attracts the attention of white businessmen looking to seize the opportunity at stealing as much from the Osage tribe as possible. Among this group of interlopers is Ernest Burkhart (Leonardo DiCaprio), whom upon arriving in Oklahoma is encouraged by his uncle William King Hale (Robert De Niro) to marry a member of the Osage as a way of inheriting their fortune. Ernest soon falls in love with and later marries Mollie (Lily Gladstone), a young Osage woman who has strong ties to her family's riches. As the white occupation of native land continues, members of the Osage tribe are repeatedly found murdered under mysterious circumstances, with some of Mollie's close family being among the most prominent victims.  One of my favourite things about movies is that in addition to being an enjoyable means of entertainment, they also function as a great method of preservation. No matter obscure the topic may be, if a film is made about it and released into the mainstream, then it has already been permanently preserved in some way. This is especially effective if the filmmaker believes that people should be made aware of something that may otherwise have been forgotten with time, and in doing so, has helped maintain its relevance with the general public. One event that is often glanced over is the Osage Indian murders, a series of slayings of wealthy members of the Native American Osage tribe during the early 20th century. However, thanks to Martin Scorsese's film \"Killers of the Flower Moon\", audiences now have the chance to be both educated and entertained about this overlooked historical occurrence in a movie that provides a sophisticated, eye-opening look at America's treatment of one particular group of their indigenous population.  Much like most of Scorsese's best known work, the film is framed as an epic, in-depth study of the dark side of human nature. We watch how the Osage tribe, who live in harmony among themselves, are forcibly thrust into the sights of the outside world after oil is found on their land. In spite of the vast wealth they have all accumulated, the Osage are unable to hold back against the large tide of white people showing up and attempting to steal away everything that is rightly theirs. Because of this, the tribe's happy existence has been compromised as they are subjected to frequent discrimination, first verbal and then physical. It is here we see the sinister plan of William King Hale come into play, where he marries off his nephew Ernest into the Osage as a way of pilfering their riches when the time is right. What makes this scheme so intriguing to watch is not only the patience required to pull it off but the ethical ramifications that result from it. Only a filmmaker like Scorsese could explore a topic like this with such complexity, and in a style that remains as timeless as ever.  Additionally, almost all of Scorsese's visual trademarks as a director are on full display here, from his wide-open cinematography designed to immerse the audience in the world of 1920s America to his creative framing of characters in shot to give a certain perspective on a scene. One in particular that stood out to me was during a conversation between Ernest and William as they discuss business regarding the Osage. We see the two seated inside a darkly lit room discussing what type of future lies ahead for the entire tribe, with Ernest choosing to remain loyal to his Osage wife Mollie, while his uncle William reminds his nephew of the important reason why he married her in the first place. Here, Scorsese places the characters in a way that makes them look out of place inside a single bright spot in the dark room. The darkness surrounding these two can be likened to a perfect visual representation of their true intentions and the supposed brightness focused on them is in actuality a metaphor for their tainted presence on everything the Osage have created up until this point.  Due to the scale of its theme and plotting, the film rightfully earns its long runtime of almost three and a half hours (206 minutes in total). This is because there are so many different facets to explore with each of the characters, as their actions and the resulting consequences make for a compelling viewing experience. While I personally think this made the film more interesting to watch, I'm not entirely sure the same can be said for casual viewers. The film's pacing is intentionally slow as a means to build tension in the air, which I believe works rather effectively, and the minimal musical score is used as a method to showcase a more realistic point of view during scenes of raw emotion. In other words, this is a film that requires patience and an attentive mind, something of which is greatly rewarded to anybody who manages to display both of these virtues. To that effect, Scorsese has made a film that is heavily reliant on atmosphere rather than the frequent action of most other Hollywood blockbusters.  In his sixth collaboration with the legendary director, Leonardo DiCaprio delivers yet another memorable performance in the role of Ernest Burkhart. What makes DiCaprio's character so intriguing is his indecisive nature, in that he is torn between supporting his own white family or his Osage wife Mollie. On one hand, Ernest's loyalty towards his birth family is what made him go ahead with his uncle's idea in the first place, while on the other hand when he truly falls for Mollie he cannot bring himself to end her along with her entire tribe. DiCaprio displays his signature range of emotion here, alternating between a strong family man and a submissive weakling doing his uncle's bidding, both of which he pulls off quite effectively.  After working on ten films together, Robert De Niro steps back from his usual spot as the Scorsese lead and into the supporting role as William King Hale, where he is essentially the main antagonist of this story. Hale is a man who is determined to weasel his way into wealth, regardless of whether or not he has truly earned it. His intentions are malicious and are only meant to serve his own personal gain, with little regard for the wellbeing of others, even his nephew. What I consider to be his worst character trait is that he believes all of his actions are justified by what the Bible says about spreading the Word of God. His claim that God wants him to participate in the genocide of an entire race of people is nothing short of evil, and he demonstrates this at numerous points throughout the film. A role like this is perfect for an actor like Robert De Niro, and what better director to show this to the world than Martin Scorsese?  However, the film's true standout would have to be Lily Gladstone as Mollie, who is truly the heart and soul of this story. Here is a woman who has experienced so much pain and heartbreak in her life, whether it's her own physical ailments or the sudden death of her relatives. Yet, despite all these hardships, Mollie remains as steadfast as ever, choosing to be a loving wife to her husband and caring mother to her young children. Mollie essentially represents all of the positive values that her tribe upholds, and she is among the last of her family who hasn't completely sold herself out to the ideals of a rich lifestyle. This is easily a career defining role for Gladstone, and she certainly has potential to be noteworthy star one day.  For the American history buff and the Martin Scorsese fan, \"Killers of the Flower Moon\" represents a fascinating look into the best of both worlds. It brings attention to an often neglected historical issue through use of another well-crafted cinematic addition to a beloved filmmaking veteran's library. As mentioned previously, it is nice to know that this story has now been effectively preserved through the medium of film, which means that future generations will be able to watch it back and learn about the horrific events that took place during this time period. After all, as the classic saying goes - those who don't learn from history are doomed to repeat it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "The Review Sentiment is Positive\n"
     ]
    }
   ],
   "source": [
    "# checking for sentiments\n",
    "# this is a positive review I took from IMDB\n",
    "review = str(input())\n",
    "sentiments(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363b094b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is long, dark, one-dimensional and boring, from the beginning you know the ending, the novel had much more emotion. The story it tells does not need that much length, it is a great disappointment and even more so after having read all those unfounded praises from some critics. The lighting and cinematography options are vulgar, there is nothing that stands out. The actors are not directed, Robert De Niro plays Robert De Niro once again, Leonardo DiCaprio is past and out of the film, only Lily Gladstone provides some authenticity and with one look she devours her companions on the screen.\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "The Review Sentiment is Negative\n"
     ]
    }
   ],
   "source": [
    "# checking the negative review\n",
    "review = str(input())\n",
    "sentiments(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263976e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
